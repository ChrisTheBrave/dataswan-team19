# -*- coding: utf-8 -*-
"""etl_script_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sv6V34LD92iSmTaTiGfw8lu3X1o9LZKC
"""

import pandas as pd
import json
import requests
import os
import numpy as np
import time
pd.set_option('display.max_columns', None)

#List of APIs

res_pay2020 = "https://openpaymentsdata.cms.gov/api/1/datastore/query/9c248e7e-7c7f-478b-ab84-ce0919d72c1c/0"
res_pay2021 = "https://openpaymentsdata.cms.gov/api/1/datastore/query/ce1d28dd-0094-5060-a036-580329439600/0"
own_pay2020 = "https://openpaymentsdata.cms.gov/api/1/datastore/query/a9a0bf48-6b96-4589-b4c2-3c5dcfbeaca2/0"
own_pay2021 = "https://openpaymentsdata.cms.gov/api/1/datastore/query/b0c03b8d-06df-58f2-8ce2-4daeffee147e/0"
gen_pay2020 = "https://openpaymentsdata.cms.gov/api/1/datastore/query/a08c4b30-5cf3-4948-ad40-36f404619019/0"
gen_pay2021 = "https://openpaymentsdata.cms.gov/api/1/datastore/query/0380bbeb-aea1-58b6-b708-829f92a48202/0"
prof_sup = "https://openpaymentsdata.cms.gov/api/1/datastore/query/23160558-6742-54ff-8b9f-cac7d514ff4e/0?offset=0&count=true&results=true&schema=true&keys=true&format=json&rowIds=false"
survey_data_overall_mips = "https://data.cms.gov/provider-data/api/1/datastore/query/a174-a962/0"
survey_data_patient_exp = 'https://data.cms.gov/provider-data/api/1/datastore/query/8c70-d353/0'



payment_list = [res_pay2020, res_pay2021,own_pay2020, own_pay2021, gen_pay2020, gen_pay2021, prof_sup, survey_data_overall_mips,survey_data_patient_exp]


dataset_list = []
for api_url in payment_list: #loop through list of apis
        response = requests.get(api_url) #make request to api
        parsed_response = json.loads(response.content) #read in json result from api pull
        pay_df = pd.DataFrame(parsed_response['results'])
        dataset_list.append(pay_df)# go to results key in loaded json and read that in as data frame

#len(dataset_list[7].columns)







"""## Subsetting original data sources for relevant columns"""

# general payments

general_payments_cols = ['record_id',
                         'teaching_hospital_ccn',
                         'product_category_or_therapeutic_area_1',
                         'Date_of_Payment',
                         'Recipient_State',
                         'Recipient_City',
                         'number_of_payments_included_in_total_amount',
                         'Total_Amount_of_Payment_USDollars',
                         'Teaching_Hospital_Name',
                         'Covered_Recipient_NPI',
                          'covered_recipient_profile_id']

columns_being_kept = [x.lower().strip() for x in general_payments_cols]


df_general_2020 = dataset_list[4]
df_general_edited_20 = df_general_2020[columns_being_kept]


df_general_2021 = dataset_list[5]
df_general_edited_21 = df_general_2021[columns_being_kept]

df_general_edited = pd.concat([df_general_edited_20,df_general_edited_21], axis = 0, ignore_index = True)



#df_general_edited.head()



# ownership payments

ownership_payments_cols = ['record_id',
    'Physician_Specialty',
'physician_first_name',
'physician_last_name',
'physician_middle_name']

own_cols_kept = [x.lower().strip() for x in ownership_payments_cols]

df_ownership_20 = dataset_list[2]
df_ownership_edited_20 = df_ownership_20[own_cols_kept]

df_ownership_21 = dataset_list[3]
df_ownership_edited_21 = df_ownership_21[own_cols_kept]

df_ownership_edited = pd.concat([df_ownership_edited_20,df_ownership_edited_21], axis = 0, ignore_index = True)
#df_ownership_edited.head()



#Patients

physician_prof = dataset_list[6]
df_physician_prof_edited = physician_prof[['covered_recipient_profile_primary_specialty','covered_recipient_profile_id']]
#df_physician_prof_edited.head()

# Survey data

##overall MIPS
survey_data_cols_mips = ['npi','facility_ccn','org_pac_id','Quality_category_score',
 'PI_category_score',
 'IA_category_score',
'Cost_category_score',
 'final_MIPS_score_without_CPB']
survey_mips_cols_kept = [x.lower().strip() for x in survey_data_cols_mips]
df_mips_survey = dataset_list[7]
df_survey_mips_edited = df_mips_survey[survey_mips_cols_kept]
survey_df = df_survey_mips_edited
#survey_df.head()

len(survey_df.columns)

# NOT GOING TO INCLUDE

##patient experience
# survey_data_pat_exp_cols = [ 'org_pac_id','prf_rate']
# survey_pat_exp_cols_kept = [x.lower().strip() for x in survey_data_pat_exp_cols]
# df_pat_exp_survey = dataset_list[8]
# df_survey_pat_exp_edited = df_pat_exp_survey[survey_pat_exp_cols_kept]
# df_survey_pat_exp_edited.head()
# survey_df_ni = pd.merge(df_survey_mips_edited,df_survey_pat_exp_edited, on = 'org_pac_id', how = 'outer')



"""## Cleaning subsetted original data

"""

# DATA SETS

# df_general_edited
# df_ownership_edited
# df_physician_prof_edited
# survey_df

#Chekcing for NA counts
#df_general_edited.isnull().sum() #number of na values in general payments

#df_general_edited.eq('').sum() #number of empty strings in each column for general payments data



#df_ownership_edited.isnull().sum() #Number of nas in ownership data

#df_ownership_edited.eq('').sum() #numeber of empty strings in ownership data

#df_physician_prof_edited.isnull().sum() #number of na values in physicains data

#df_physician_prof_edited.eq('').sum() #number of empty strings in physicians data

#survey_df.isnull().sum() #number of navalues in overall MIPS survey data

#survey_df.eq('').sum() #number of entries in survey data with empty string entires



#dropping columns that are missing more than 40% of data
df_general_edited = df_general_edited.drop(columns = ['product_category_or_therapeutic_area_1'])
df_ownership_edited = df_ownership_edited.drop(columns = ['physician_middle_name'])
survey_df = survey_df.drop(columns = ['pi_category_score','ia_category_score'])



#imputing missing values with mode/most frequent categories for categorical columns

#physician_specialty
df_ownership_edited['physician_specialty'] = df_ownership_edited[['physician_specialty']].apply(lambda x: x.str.strip()).replace('', df_ownership_edited['physician_specialty'].value_counts().index[0])

#covered_recipient_profile_primary_specialty
df_physician_prof_edited['covered_recipient_profile_primary_specialty'] = df_physician_prof_edited[['covered_recipient_profile_primary_specialty']].apply(lambda x: x.str.strip()).replace('', df_physician_prof_edited['covered_recipient_profile_primary_specialty'].value_counts().index[0])

#df_ownership_edited.eq('').sum() # check imputation for ownership

#df_physician_prof_edited.eq('').sum() #check imputation for physician

# replace missing value entires for primary key and foreign key columns with default values

#covered_recipient_npi
default_npi_vals = [str(i) for i in np.arange(int(max(df_general_edited['covered_recipient_npi'])) + 1 , int(max(df_general_edited['covered_recipient_npi'])) + df_general_edited.eq('').sum()['covered_recipient_npi'] + 1)]
df_general_edited['covered_recipient_npi'] = df_general_edited[['covered_recipient_npi']].apply(lambda x: x.str.strip()).replace('', default_npi_vals[0])

#covered_recipient_profile_id
default_profile_vals = [str(i) for i in np.arange(int(max(df_general_edited['covered_recipient_profile_id'])) + 1 , int(max(df_general_edited['covered_recipient_profile_id'])) + df_general_edited.eq('').sum()['covered_recipient_profile_id'] + 1)]
df_general_edited['covered_recipient_profile_id'] = df_general_edited[['covered_recipient_profile_id']].apply(lambda x: x.str.strip()).replace('', default_profile_vals[0])

#check that empty values were replaced with default values

#df_general_edited.eq('').sum()

# making entires lower case
general = df_general_edited.apply(lambda x: x.astype(str).str.lower()) #Make row entries lower case

#general

#Remove leading and trailing white space
general_final = general.apply(lambda x: x.astype(str).str.strip())

#general_final

"""## Functions to help with ETL

"""

# def table_generator2(columns_associated_with_table_I_want_to_generate,dfs_to_look_through,primary_key):
#     """goes through thables provided and returns columns that you want from each table in a single table

#     keyword arguments:

#     :param columns_associated_with_table_I_want_to_generate: list list of columns you want in your final table
#     :param dfs_to_look_through: list of pandas dataframes list of dataframes you want to look through
#     :param primary_key: str the primary key that is shared among all dataframes you are looking through
#     :return: pandas dataframe - the single datafram/table that results from you merging all of the columns you wanted together

#     Looks through dfs_to_look_through for columns_associated_with_table_I_want_to_generate and outter joins all of them together, returning the result.
#     """
#     empt_df = pd.DataFrame(columns = [primary_key])
#     for api_payment_df in dfs_to_look_through: #loop through list of apis
#         correct_columns = []
#         existing_columns = []
#         for column in api_payment_df.columns:
#             if column in columns_associated_with_table_I_want_to_generate:
#                 correct_columns.append(column)
#             if column in empt_df.columns:
#                 existing_columns.append(column)
#         #print(correct_columns)
#         if len(correct_columns)>0:
#             empt_df = pd.merge(empt_df, api_payment_df[correct_columns], on = existing_columns, how = 'outer')
#         #print(correct_columns)
#         #print(existing_columns, '*********************')
#     return empt_df

def col_clean(lst_of_columns):
  cleaned = [x.lower().strip() for x in lst_of_columns]
  return cleaned

"""## Making final tables"""

#os.listdir()

kept_columns = pd.read_csv('/content/kept_columns_from_data_sources - columns_pupulating_dashboard (5).csv')

payments_columns = col_clean(kept_columns[kept_columns['Group'] == 1]['field_available_in_data'].unique())
physician_columns = col_clean(kept_columns[kept_columns['Group'] == 2]['field_available_in_data'].unique())
patients_columns = col_clean(kept_columns[kept_columns['Group'] == 3]['field_available_in_data'].unique())
survey_columns = col_clean(kept_columns[kept_columns['Group'] == 4]['field_available_in_data'].unique())
hospital_columns = col_clean(kept_columns[kept_columns['Group'] == 5]['field_available_in_data'].unique())

#Payments Table
payments_table = general_final[payments_columns]
#payments_table.head(1)

#Physician Table
gen_phys = general_final[['covered_recipient_profile_id','record_id', 'covered_recipient_npi']]
own_phys = df_ownership_edited[['physician_specialty','physician_first_name','physician_last_name','record_id']]
physicians_table = pd.merge(gen_phys, own_phys, on = 'record_id', how = 'outer', copy = False)

#physicians_table.head()

# Patients Table
patients_table = df_physician_prof_edited[patients_columns]
#patients_table.head()

#Reviews Table
survey_columns = ['quality_category_score',
 'cost_category_score',
 'final_mips_score_without_cpb',
 'facility_ccn',
'npi']
reviews_table = survey_df[survey_columns]
#reviews_table.head()

#Hospital Table
hospital_table = df_general_edited[hospital_columns]
#hospital_table.head()

# Collecting all tables into single object

tables_list = [payments_table, physicians_table, patients_table, reviews_table,hospital_table]

# End of actual tables

# Exporting Tables

physicians_table_test = physicians_table.tail(2)


#physicians_table_test.to_csv('physicians_table_test.csv', index = False)

physicians_table_test = physicians_table_test.fillna('00')
physicians_table_test.to_csv('physicians_table_test.csv', index = False)





